apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: eks-poc
  region: us-east-1
  version: "1.30"
  tags:
    wp:terraform: "false"
    wp:environment: "dev"
    wp:cost-center: "ops"
    wp:owner: "ops"
    wp:managed-by: "eksctl"
   # karpenter.sh/discovery: eks-poc  #${CLUSTER_NAME}

vpc:
  id: vpc-0f941eed71c3b0179
  autoAllocateIPv6: false
  manageSharedNodeSecurityGroupRules: true
  nat:
    gateway: Disable
  #publicAccessCIDRs: ["10.0.2.0/24", "10.0.9.0/25"]
  securityGroup: sg-06a0beefd0ed45a07
  subnets:
    private:
      us-east-1a: { id: subnet-0ebeafd6054e83d84 }
      us-east-1b: { id: subnet-0e62b2a66ea4235c7 }
     # us-east-1c: { id: subnet-0564dca4816439969 }
    public:
      us-east-1a: { id: subnet-0441e1c0571e6d4a6 }
      us-east-1b: { id: subnet-0b352436511bed6c4 }
      #us-east-1c: { id: subnet-02ab36d3b3700e7fa }
  clusterEndpoints:
    privateAccess: false
    publicAccess: true
cloudWatch:
   clusterLogging:
    enableTypes: ["api", "audit", "authenticator", "controllerManager", "scheduler"]
    logRetentionInDays: 7
iam:
 vpcResourceControllerPolicy: true
 withOIDC: true
 podIdentityAssociations: 
 #serviceAccounts:	
  - namespace: kube-system
    serviceAccountName: aws-load-balancer-controller
    roleName: pod-identity-role-alb
    wellKnownPolicies:
      awsLoadBalancerController: true

  - namespace: kube-system
    serviceAccountName: efs-csi-controller-sa
    roleName: pod-identity-role-efs
    wellKnownPolicies:
      efsCSIController: true      

  - namespace: kube-system
    serviceAccountName: external-dns
    roleName: pod-identity-role-external-dns
    wellKnownPolicies:
      externalDNS: true          

  - namespace: cert-manager
    serviceAccountName: cert-manager
    roleName: pod-identity-role-cert-manager
    wellKnownPolicies:
      certManager: true         

  - namespace: kube-system
    serviceAccountName: cluster-autoscaler
    roleName: pod-identity-role-cluster-autoscaler
    wellKnownPolicies:
      autoScaler: true  

  - namespace: amazon-cloudwatch
    serviceAccountName: aws-node
    roleName: pod-identity-role-cloudwatch-agent
    permissionPolicyARNs: ["arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy"]

managednodeGroups:
  - name: eks-pooc-ng
    instanceType: t3a.medium
    amiFamily: AmazonLinux2023
    #privateNetworking: true # Ensures nodes are launched in private subnets
   # updateConfig:
    #  maxUnavailablePercentage: 10
    disableIMDSv1: false
    disablePodIMDS: false
    desiredCapacity: 2
    minSize: 2
    maxSize: 2
    volumeSize: 20
    volumeType: gp3
#    volumeEncrypted: true
#    volumeKmsKeyID:  # please see https://docs.aws.amazon.com/autoscaling/ec2/userguide/key
    ssh: # use existing EC2 key
      allow: true
      enableSsm: false
      publicKeyPath: "/root/.ssh/devops.pub"
    securityGroups:
      withShared: true
      attachIDs: sg-06a0beefd0ed45a07
    maxPodsPerNode: 17
    subnets:
      - subnet-0ebeafd6054e83d84
      - subnet-0e62b2a66ea4235c7
  #    - subnet-0564dca4816439969	 
    iam:
      withAddonPolicies:
        imageBuilder: true
        autoScaler: true
        externalDNS: true
        certManager: true
        #appMesh: true
        ebs: true
        albIngress: true
        xRay: true
        cloudWatch: true
        awsLoadBalancerController: true
        efs: false
        fsx: false
      #attachPolicyARNs: https://dev.to/aws-builders/eks-iam-deep-dive-136d https://schema.eksctl.io/
        # - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
         #- arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
         #- arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
       # AWS Managed or Customer Managed IAM Policy ARN.
         #- arn:aws:iam::aws:policy/AmazonS3FullAccess
      #instanceProfileARN: "arn:aws:iam::509399617800:instance-profile/eksNodeRole"
      #instanceRoleARN: "arn:aws:iam::509399617800:role/eksNodeRole"
    tags:
      alpha.eksctl.io/cluster-name: eks-poc
      alpha.eksctl.io/nodegroup-name: "ops_build_eks_nodegroup"
      alpha.eksctl.io/nodegroup-type: "managed"
      nodegroup-role: "worker-node"
       # EC2 tags required for cluster-autoscaler auto-discovery - these tags are automatically applied to a managed nodegroup autoscaling group
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/managednodes-quickstart: "owned"   
    labels: 
      nodegroup-role: "worker" 

addons:
  #- name: aws-ebs-csi-driver
  #  version: latest
  - name: eks-pod-identity-agent
    version: latest
    resolveConflicts: overwrite
  - name: vpc-cni
    version: latest # Example version
    resolveConflicts: overwrite
    #attachPolicyARNs:
     #- arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
    # Optional: Add specific config for the CNI if needed
  - name: kube-proxy
    version: latest
    resolveConflicts: overwrite
    # Optional: Configure settings here
  - name: coredns
    version: latest 
    resolveConflicts: overwrite
    
#  - name: aws-ebs-csi-driver # Example for a common add-on
#    wellKnownPolicies: # Simplifies IAM setup
#      ebsCSIController: true
  
  
addonsConfig:  
# automatically resolve (and apply) the recommended pod identity configuration  
   autoApplyPodIdentityAssociations: true

#karpenter:
 # version: '0.37.0' # Exact version must be provided
 # createServiceAccount: true # default is false
 # withSpotInterruptionQueue: true #adds all required policies and rules for supporting Spot Interruption Queue, default is false